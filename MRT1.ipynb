{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download Youtube Video\n",
    "Download youtube video using api/library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytube\n",
    "video_link = \"https://www.youtube.com/watch?v=QTB1YiWxxKU\"\n",
    "video_file = pytube.YouTube(video_link)\n",
    "stream = video_file.streams.first()\n",
    "stream.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract / Download Subtitle of Video\n",
    "Extract Subtiles of Youtube Video and create a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "subtitles = YouTubeTranscriptApi.get_transcript('QTB1YiWxxKU')\n",
    "processed_transcript = ''\n",
    "for sub in subtitles:\n",
    "    processed_transcript += sub['text'] + ' '\n",
    "print(processed_transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Inverted Index of a extracted transcript\n",
    "After cleaning the subtitles create an inverted index and store in CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import itertools\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword_punctuations(content):\n",
    "    tokens = nltk.word_tokenize(content)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filter_stopwords = [w for w in words if not w in stop_words]\n",
    "    return filter_stopwords\n",
    "\n",
    "def content_stemming(filtered_content):\n",
    "    stemmed_content = []\n",
    "    ps =  nltk.PorterStemmer()\n",
    "    for token in filtered_content:\n",
    "        word_stem = ps.stem(token)\n",
    "        stemmed_content.append(word_stem.lower())\n",
    "        \n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_removal = remove_stopword_punctuations(processed_transcript)\n",
    "stemmed_tokens = content_stemming(stopword_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('invertedindex.csv', mode='w') as invertedindex:\n",
    "    employee_writer = csv.writer(invertedindex, delimiter=',')\n",
    "\n",
    "    employee_writer.writerow(['Term', 'Frequency'])\n",
    "    for token in stemmed_tokens:\n",
    "        employee_writer.writerow([token, stemmed_tokens.count(token)])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataframe = pd.read_csv('invertedindex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_repeated_terms = dataframe.drop_duplicates(subset=['Term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invertedindex = remove_repeated_terms\n",
    "invertedindex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy.editor as mp\n",
    "video_clip = mp.VideoFileClip(r\"STOP WASTING TIME - Best Motivational Video.mp4\")\n",
    "video_clip.audio.write_audiofile(\"audiofile.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seperate Voice and Music from Audio File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio('audiofile.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!spleeter separate -o output/ audiofile.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Voice in Video')\n",
    "Audio('output/audiofile/vocals.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Music in Video')\n",
    "Audio('output/audiofile/accompaniment.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate MFFC of Voice and Music File\n",
    "Python Speech Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "from python_speech_features import logfbank\n",
    "import scipy.io.wavfile as wav\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voice\n",
    "Plot MFCC\n",
    "Save MFFC of Voice in File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rate1,sig1) = wav.read(\"output/audiofile/vocals.wav\")\n",
    "mfcc_features_voice = mfcc(sig1,rate1)\n",
    "f = open(\"mfcc_features_voice.txt\", \"w\")\n",
    "for row in mfcc_features_voice:\n",
    "    np.savetxt(f, row)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mfcc_features_voice)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Music\n",
    "Plot MFFC\n",
    "Save MFFC of Music in File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(rate2,sig2) = wav.read(\"output/audiofile/accompaniment.wav\")\n",
    "mfcc_features_music = mfcc(sig2,rate2)\n",
    "f = open(\"mfcc_features_music.txt\", \"w\")\n",
    "for row in mfcc_features_music:\n",
    "    np.savetxt(f, row)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mfcc_features_music)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MFCC using Librosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path_vocals = 'output/audiofile/vocals.wav'\n",
    "x, sr = librosa.load(audio_path_vocals)\n",
    "print(type(x), type(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path_vocals = 'output/audiofile/vocals.wav'\n",
    "x, sr = librosa.load(audio_path_vocals)\n",
    "print(type(x), type(sr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = librosa.stft(x)\n",
    "Xdb = librosa.amplitude_to_db(abs(X))\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='log')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Video Frames\n",
    "Plot Histogram of Video Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "from FrameExtractor import FrameExtractor\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameE = FrameExtractor('STOP WASTING TIME - Best Motivational Video.mp4')\n",
    "FrameE.get_video_duration()\n",
    "FrameE.get_n_images(every_x_frame=1000)\n",
    "FrameE.extract_frames(every_x_frame=1000,img_name='kf',dest_path='key_images')\n",
    "def show_image(path):\n",
    "    image = cv2.imread(path)\n",
    "    plt.imshow(image)\n",
    "    plt.show()   \n",
    "path, dirs, files = next(os.walk(\"key_images/\"))\n",
    "file_count = len(files)\n",
    "print(file_count)\n",
    "file=open(\"histogram.txt\",\"w\")\n",
    "file.close()\n",
    "for i in range(file_count):\n",
    "    key_frame = 'key_images/kf_'+ str(i) +'.jpg'\n",
    "    show_image(key_frame)\n",
    "    im = cv2.imread(key_frame)\n",
    "    # calculate mean value from RGB channels and flatten to 1D array\n",
    "    vals = im.mean(axis=2).flatten()\n",
    "    #print(vals)\n",
    "    file=open(\"histogram.txt\",\"a+\")\n",
    "    histogram = repr(vals)\n",
    "    file.write(histogram)\n",
    "    file.writelines(\"\\n\")   \n",
    "    b, bins, patches = plt.hist(vals, 255)\n",
    "    #print(bins)\n",
    "    all_bins=repr(bins)\n",
    "    file.write(all_bins)\n",
    "    file.writelines(\"\\n\")\n",
    "    plt.xlim([0,255])\n",
    "    plt.show()\n",
    "    #file.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/47899253/how-to-plot-3d-histogram-of-an-image-in-opencv\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"key_images/kf_1.jpg\")\n",
    "img += cv2.imread(\"key_images/kf_2.jpg\")\n",
    "img += cv2.imread(\"key_images/kf_3.jpg\")\n",
    "img += cv2.imread(\"key_images/kf_4.jpg\")\n",
    "img += cv2.imread(\"key_images/kf_5.jpg\")\n",
    "img += cv2.imread(\"key_images/kf_6.jpg\")\n",
    "    \n",
    "\n",
    "hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "h,s,v = cv2.split(hsv)\n",
    "fig = plt.figure(figsize=(30, 40))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for x, c, z in zip([h,s,v], ['r', 'g', 'b'], [30, 20, 10]):\n",
    "    xs = np.arange(256)\n",
    "    ys = cv2.calcHist([x], [0], None, [256], [0,256])\n",
    "    cs = [c] * len(xs)\n",
    "    cs[0] = 'c'\n",
    "    ax.bar(xs, ys.ravel(), zs=z, zdir='y', color=cs, alpha=0.8)\n",
    "\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Z')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
